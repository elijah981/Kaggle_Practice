{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Machine Learning Solution using\n",
    "# Pipelines to get incrementally better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collecting Data\n",
    "2. Data Exploration\n",
    "3. Feature Engineering\n",
    "4. Model building\n",
    "5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "#Scikit Learn Base\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scikit Learn tools\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_test = pd.read_csv('input/test.csv')\n",
    "combine = [df_train, df_test]\n",
    "df_train.name = 'Train'\n",
    "df_test.name = 'Test'\n",
    "\n",
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=14)\n",
    "target = df_train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_survived(estimator, kfolds, data, target):\n",
    "    scores = []\n",
    "    train = data.copy()\n",
    "    for i, (train_index, test_index) in enumerate(kfolds.split(target)):\n",
    "        training = train.iloc[train_index,:]\n",
    "        valid = train.iloc[test_index,:]\n",
    "        tr_label = target.iloc[train_index]\n",
    "        val_label = target.iloc[test_index]\n",
    "        estimator.fit(training, tr_label)\n",
    "        pred = estimator.predict(valid)\n",
    "        score = accuracy_score(y_pred=pred, y_true=val_label)\n",
    "        scores.append(score)\n",
    "    return round(np.mean(scores),3)\n",
    "\n",
    "def get_coef(clsf, features):\n",
    "    imp = clsf.steps[1][1].coef_.tolist()\n",
    "    results = pd.DataFrame({'Features':features,'Score':imp})\n",
    "    results = results.sort_values(by='Score', ascending=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline\n",
    "As baseline we will predict all women survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 in progress\n",
      "Score : 0.788\n",
      "----------------------------------------\n",
      "Fold 1 in progress\n",
      "Score : 0.787\n",
      "----------------------------------------\n",
      "Fold 2 in progress\n",
      "Score : 0.781\n",
      "----------------------------------------\n",
      "Fold 3 in progress\n",
      "Score : 0.798\n",
      "----------------------------------------\n",
      "Fold 4 in progress\n",
      "Score : 0.781\n",
      "----------------------------------------\n",
      "Baseline: 0.787 +- 0.006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  \n",
       "0        0         A/5 21171    7.2500          NaN        S  \n",
       "1        0          PC 17599   71.2833          C85        C  \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3        0            113803   53.1000         C123        S  \n",
       "4        0            373450    8.0500          NaN        S  \n",
       "5        0            330877    8.4583          NaN        Q  \n",
       "6        0             17463   51.8625          E46        S  \n",
       "7        1            349909   21.0750          NaN        S  \n",
       "8        2            347742   11.1333          NaN        S  \n",
       "9        0            237736   30.0708          NaN        C  \n",
       "10       1           PP 9549   16.7000           G6        S  \n",
       "11       0            113783   26.5500         C103        S  \n",
       "12       0         A/5. 2151    8.0500          NaN        S  \n",
       "13       5            347082   31.2750          NaN        S  \n",
       "14       0            350406    7.8542          NaN        S  \n",
       "15       0            248706   16.0000          NaN        S  \n",
       "16       1            382652   29.1250          NaN        Q  \n",
       "17       0            244373   13.0000          NaN        S  \n",
       "18       0            345763   18.0000          NaN        S  \n",
       "19       0              2649    7.2250          NaN        C  \n",
       "20       0            239865   26.0000          NaN        S  \n",
       "21       0            248698   13.0000          D56        S  \n",
       "22       0            330923    8.0292          NaN        Q  \n",
       "23       0            113788   35.5000           A6        S  \n",
       "24       1            349909   21.0750          NaN        S  \n",
       "25       5            347077   31.3875          NaN        S  \n",
       "26       0              2631    7.2250          NaN        C  \n",
       "27       2             19950  263.0000  C23 C25 C27        S  \n",
       "28       0            330959    7.8792          NaN        Q  \n",
       "29       0            349216    7.8958          NaN        S  \n",
       "..     ...               ...       ...          ...      ...  \n",
       "861      0             28134   11.5000          NaN        S  \n",
       "862      0             17466   25.9292          D17        S  \n",
       "863      2          CA. 2343   69.5500          NaN        S  \n",
       "864      0            233866   13.0000          NaN        S  \n",
       "865      0            236852   13.0000          NaN        S  \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
       "867      0          PC 17590   50.4958          A24        S  \n",
       "868      0            345777    9.5000          NaN        S  \n",
       "869      1            347742   11.1333          NaN        S  \n",
       "870      0            349248    7.8958          NaN        S  \n",
       "871      1             11751   52.5542          D35        S  \n",
       "872      0               695    5.0000  B51 B53 B55        S  \n",
       "873      0            345765    9.0000          NaN        S  \n",
       "874      0         P/PP 3381   24.0000          NaN        C  \n",
       "875      0              2667    7.2250          NaN        C  \n",
       "876      0              7534    9.8458          NaN        S  \n",
       "877      0            349212    7.8958          NaN        S  \n",
       "878      0            349217    7.8958          NaN        S  \n",
       "879      1             11767   83.1583          C50        C  \n",
       "880      1            230433   26.0000          NaN        S  \n",
       "881      0            349257    7.8958          NaN        S  \n",
       "882      0              7552   10.5167          NaN        S  \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
       "885      5            382652   29.1250          NaN        Q  \n",
       "886      0            211536   13.0000          NaN        S  \n",
       "887      0            112053   30.0000          B42        S  \n",
       "888      2        W./C. 6607   23.4500          NaN        S  \n",
       "889      0            111369   30.0000         C148        C  \n",
       "890      0            370376    7.7500          NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfolds.split(target)):\n",
    "    df_train['prediction'] = 0 #Initialize all predictions as Not Survived (0)\n",
    "    print(\"Fold {} in progress\".format(i))\n",
    "    result = df_train['Survived'].iloc[test_index] #Get actual answers \n",
    "    df_train['prediction'].loc[df_train.Sex == 'female'] = 1 #Predict all using method\n",
    "    pred = df_train['prediction'].iloc[test_index] #Get predictions for test index\n",
    "    score = accuracy_score(y_pred=pred, y_true=result) #Calculate score\n",
    "    scores.append(score)\n",
    "    print(\"Score : {}\".format(round(score,3)))\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "print(\"Baseline: {} +- {}\".format(round(np.mean(scores),3), round(np.std(scores),3)))\n",
    "df_train.drop('prediction', axis=1)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Imputing and Dropping advanced features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selects columns from the dataframe on which other processing is to be done\n",
    "    attribute_names = list of column names to be selected\n",
    "    \"\"\"\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[(self.attribute_names)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    General Imputer to impute missing values by applying certain functions on a group of columns\n",
    "    col_impute - column into which values are imputed\n",
    "    col_group - column groups which are taken into account\n",
    "    impute_method - choose from 'median' or 'average'\n",
    "    \"\"\"\n",
    "    def __init__(self, col_impute, col_group, impute_method='median'):\n",
    "        self.col_impute = col_impute\n",
    "        self.col_group = col_group\n",
    "        self.impute_method = impute_method\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        \n",
    "        grouped = df.groupby(self.col_group)\n",
    "        \n",
    "        def imputer_median(series):\n",
    "            return series.fillna(series.median())\n",
    "\n",
    "        def imputer_average(series):\n",
    "            return series.fillna(series.mean())\n",
    "        \n",
    "        if self.impute_method == 'median':\n",
    "            df[(self.col_impute)] = grouped[self.col_impute].transform(imputer_median)\n",
    "            return df\n",
    "        elif self.impute_method == 'average':\n",
    "            df[(self.col_impute)] = grouped[self.col_impute].transform(imputer_average)\n",
    "            return df\n",
    "        else:\n",
    "            return np.nan\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbarkedImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputes values into Embarked variable\n",
    "    \"\"\"\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        return None\n",
    "    def fit(self, X):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        # deep copy the df\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Clean up fares.\n",
    "        value_to_input = df['Embarked'].mode()\n",
    "        value_to_input = value_to_input[0]\n",
    "        \n",
    "        df.loc[(df['Embarked'].isnull()),['Embarked']] = value_to_input\n",
    "\n",
    "        return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Embarked       889 non-null object\n",
      "prediction     891 non-null int64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 69.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare  \\\n",
       "0            1         0       3    male  22.0      1      0   7.2500   \n",
       "1            2         1       1  female  38.0      1      0  71.2833   \n",
       "2            3         1       3  female  26.0      0      0   7.9250   \n",
       "3            4         1       1  female  35.0      1      0  53.1000   \n",
       "4            5         0       3    male  35.0      0      0   8.0500   \n",
       "5            6         0       3    male   NaN      0      0   8.4583   \n",
       "6            7         0       1    male  54.0      0      0  51.8625   \n",
       "7            8         0       3    male   2.0      3      1  21.0750   \n",
       "8            9         1       3  female  27.0      0      2  11.1333   \n",
       "9           10         1       2  female  14.0      1      0  30.0708   \n",
       "\n",
       "  Embarked  prediction  \n",
       "0        S           0  \n",
       "1        C           1  \n",
       "2        S           1  \n",
       "3        S           1  \n",
       "4        S           0  \n",
       "5        Q           0  \n",
       "6        S           0  \n",
       "7        S           0  \n",
       "8        S           1  \n",
       "9        C           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_2 = df_train.drop(['Name','Ticket','Cabin'], axis=1)\n",
    "train_2.info()\n",
    "train_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "CAT_ATTRIBS = ['Sex','Embarked']\n",
    "NUM_ATTRIBS = ['Pclass','Age','SibSp','Parch','Fare']\n",
    "\n",
    "# map transformers on variables\n",
    "my_mapper = DataFrameMapper([\n",
    "    ('Sex', LabelBinarizer()),\n",
    "    ('Embarked', LabelBinarizer()),\n",
    "    ], input_df=True)\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('Embarked_imputer', EmbarkedImputer()),\n",
    "    ('label_binarizer_df', my_mapper),\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('Fare_imputer', GeneralImputer(col_impute='Fare',col_group=['Sex','Pclass'], impute_method='median')),\n",
    "    ('Age_imputer', GeneralImputer(col_impute='Age',col_group=['Sex','Pclass'], impute_method='median')),\n",
    "    ('Selector', DataFrameSelector(NUM_ATTRIBS)),\n",
    "    ('Scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('Num_pipeline', numerical_pipeline),\n",
    "    ('Cat_pipeline', categorical_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared = full_pipeline.fit_transform(train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 13s\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=10, min_samples_split=7,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "________________________________________\n",
      "0.8316498316498316\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'bootstrap': False, 'max_features': 0.6, 'min...         0.819304   \n",
      "1    {'bootstrap': False, 'max_features': 0.6, 'min...         0.823793   \n",
      "2    {'bootstrap': False, 'max_features': 0.6, 'min...         0.826038   \n",
      "3    {'bootstrap': False, 'max_features': 0.6, 'min...         0.820426   \n",
      "4    {'bootstrap': False, 'max_features': 0.6, 'min...         0.821549   \n",
      "5    {'bootstrap': False, 'max_features': 0.6, 'min...         0.822671   \n",
      "6    {'bootstrap': False, 'max_features': 0.6, 'min...         0.826038   \n",
      "7    {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "8    {'bootstrap': False, 'max_features': 0.6, 'min...         0.822671   \n",
      "9    {'bootstrap': False, 'max_features': 0.6, 'min...         0.812570   \n",
      "10   {'bootstrap': False, 'max_features': 0.6, 'min...         0.810325   \n",
      "11   {'bootstrap': False, 'max_features': 0.6, 'min...         0.813692   \n",
      "12   {'bootstrap': False, 'max_features': 0.6, 'min...         0.813692   \n",
      "13   {'bootstrap': False, 'max_features': 0.6, 'min...         0.817059   \n",
      "14   {'bootstrap': False, 'max_features': 0.6, 'min...         0.808081   \n",
      "15   {'bootstrap': False, 'max_features': 0.6, 'min...         0.809203   \n",
      "16   {'bootstrap': False, 'max_features': 0.6, 'min...         0.813692   \n",
      "17   {'bootstrap': False, 'max_features': 0.6, 'min...         0.811448   \n",
      "18   {'bootstrap': False, 'max_features': 0.6, 'min...         0.811448   \n",
      "19   {'bootstrap': False, 'max_features': 0.6, 'min...         0.810325   \n",
      "20   {'bootstrap': False, 'max_features': 0.6, 'min...         0.811448   \n",
      "21   {'bootstrap': False, 'max_features': 0.6, 'min...         0.808081   \n",
      "22   {'bootstrap': False, 'max_features': 0.6, 'min...         0.811448   \n",
      "23   {'bootstrap': False, 'max_features': 0.6, 'min...         0.810325   \n",
      "24   {'bootstrap': False, 'max_features': 0.6, 'min...         0.811448   \n",
      "25   {'bootstrap': False, 'max_features': 0.6, 'min...         0.808081   \n",
      "26   {'bootstrap': False, 'max_features': 0.6, 'min...         0.806958   \n",
      "27   {'bootstrap': False, 'max_features': 0.7, 'min...         0.827160   \n",
      "28   {'bootstrap': False, 'max_features': 0.7, 'min...         0.821549   \n",
      "29   {'bootstrap': False, 'max_features': 0.7, 'min...         0.828283   \n",
      "..                                                 ...              ...   \n",
      "132  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.799102   \n",
      "133  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.797980   \n",
      "134  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.803591   \n",
      "135  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.815937   \n",
      "136  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.815937   \n",
      "137  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.810325   \n",
      "138  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.819304   \n",
      "139  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.819304   \n",
      "140  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.812570   \n",
      "141  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "142  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.809203   \n",
      "143  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.813692   \n",
      "144  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.810325   \n",
      "145  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "146  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "147  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "148  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.801347   \n",
      "149  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.809203   \n",
      "150  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.803591   \n",
      "151  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.804714   \n",
      "152  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.802469   \n",
      "153  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.804714   \n",
      "154  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.804714   \n",
      "155  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.803591   \n",
      "156  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.802469   \n",
      "157  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.801347   \n",
      "158  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.799102   \n",
      "159  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.796857   \n",
      "160  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.805836   \n",
      "161  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.030385  \n",
      "1          0.035216  \n",
      "2          0.037670  \n",
      "3          0.026424  \n",
      "4          0.031169  \n",
      "5          0.031237  \n",
      "6          0.029158  \n",
      "7          0.031266  \n",
      "8          0.028793  \n",
      "9          0.024943  \n",
      "10         0.029485  \n",
      "11         0.030818  \n",
      "12         0.028501  \n",
      "13         0.033009  \n",
      "14         0.022441  \n",
      "15         0.025461  \n",
      "16         0.030356  \n",
      "17         0.025603  \n",
      "18         0.024032  \n",
      "19         0.026491  \n",
      "20         0.030302  \n",
      "21         0.029589  \n",
      "22         0.028817  \n",
      "23         0.024411  \n",
      "24         0.027706  \n",
      "25         0.022441  \n",
      "26         0.028648  \n",
      "27         0.027632  \n",
      "28         0.025108  \n",
      "29         0.024097  \n",
      "..              ...  \n",
      "132        0.015629  \n",
      "133        0.017678  \n",
      "134        0.020962  \n",
      "135        0.027660  \n",
      "136        0.025027  \n",
      "137        0.025015  \n",
      "138        0.024119  \n",
      "139        0.023646  \n",
      "140        0.027811  \n",
      "141        0.030618  \n",
      "142        0.033896  \n",
      "143        0.027016  \n",
      "144        0.030923  \n",
      "145        0.023731  \n",
      "146        0.024064  \n",
      "147        0.025858  \n",
      "148        0.026953  \n",
      "149        0.024301  \n",
      "150        0.025599  \n",
      "151        0.022162  \n",
      "152        0.024762  \n",
      "153        0.020153  \n",
      "154        0.027265  \n",
      "155        0.020029  \n",
      "156        0.018137  \n",
      "157        0.023552  \n",
      "158        0.021517  \n",
      "159        0.017558  \n",
      "160        0.017820  \n",
      "161        0.017576  \n",
      "\n",
      "[162 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier - Grid Search\n",
    "param_grid = [\n",
    "    {\n",
    "        'bootstrap':[False, True],\n",
    "        'n_estimators':[80,90,100],\n",
    "        'max_features':[0.6,0.7,0.8],\n",
    "        'min_samples_leaf':[10,12,14],\n",
    "        'min_samples_split':[3,5,7]\n",
    "    },\n",
    "]\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "# grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='neg_mean_squared_error', refit=True)\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "\n",
    "%time grid_search.fit(train_prepared,train_2['Survived'])\n",
    "\n",
    "#let's see the best estimator\n",
    "best_rfc = grid_search.best_estimator_\n",
    "print(best_rfc)\n",
    "print(\"_\"*40)\n",
    "#with its score\n",
    "# print(np.sqrt(-grid_search.best_score_))\n",
    "print(grid_search.best_score_)\n",
    "print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.7, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=7,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.9 s\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "              max_features=0.3, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=8, min_samples_split=17,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "________________________________________\n",
      "0.7384960718294051\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.704826   \n",
      "1    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.728395   \n",
      "2    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.734007   \n",
      "3    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.704826   \n",
      "4    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.727273   \n",
      "5    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.723906   \n",
      "6    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.705948   \n",
      "7    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.723906   \n",
      "8    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.723906   \n",
      "9    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.710438   \n",
      "10   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.721661   \n",
      "11   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.728395   \n",
      "12   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.705948   \n",
      "13   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.726150   \n",
      "14   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.726150   \n",
      "15   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.709315   \n",
      "16   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.729517   \n",
      "17   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.723906   \n",
      "18   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.704826   \n",
      "19   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.728395   \n",
      "20   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.734007   \n",
      "21   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.700337   \n",
      "22   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.721661   \n",
      "23   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.728395   \n",
      "24   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.701459   \n",
      "25   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.729517   \n",
      "26   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.730640   \n",
      "27   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.729517   \n",
      "28   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.719416   \n",
      "29   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.726150   \n",
      "..                                                 ...              ...   \n",
      "78   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.714927   \n",
      "79   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.731762   \n",
      "80   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.730640   \n",
      "81   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.710438   \n",
      "82   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.735129   \n",
      "83   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.730640   \n",
      "84   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.710438   \n",
      "85   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.730640   \n",
      "86   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.731762   \n",
      "87   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.717172   \n",
      "88   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.727273   \n",
      "89   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.732884   \n",
      "90   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.722783   \n",
      "91   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.725028   \n",
      "92   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.738496   \n",
      "93   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.716049   \n",
      "94   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.721661   \n",
      "95   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.720539   \n",
      "96   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.701459   \n",
      "97   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.725028   \n",
      "98   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.731762   \n",
      "99   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.708193   \n",
      "100  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.736251   \n",
      "101  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.726150   \n",
      "102  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.719416   \n",
      "103  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.729517   \n",
      "104  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.723906   \n",
      "105  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.719416   \n",
      "106  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.729517   \n",
      "107  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.736251   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.036999  \n",
      "1          0.057757  \n",
      "2          0.057995  \n",
      "3          0.044831  \n",
      "4          0.055552  \n",
      "5          0.054600  \n",
      "6          0.038804  \n",
      "7          0.059212  \n",
      "8          0.056185  \n",
      "9          0.035849  \n",
      "10         0.057585  \n",
      "11         0.059618  \n",
      "12         0.039449  \n",
      "13         0.054724  \n",
      "14         0.058558  \n",
      "15         0.044746  \n",
      "16         0.056254  \n",
      "17         0.065330  \n",
      "18         0.043561  \n",
      "19         0.063742  \n",
      "20         0.053957  \n",
      "21         0.040296  \n",
      "22         0.056428  \n",
      "23         0.058691  \n",
      "24         0.039238  \n",
      "25         0.055888  \n",
      "26         0.061291  \n",
      "27         0.047403  \n",
      "28         0.059277  \n",
      "29         0.062626  \n",
      "..              ...  \n",
      "78         0.036582  \n",
      "79         0.059560  \n",
      "80         0.059146  \n",
      "81         0.040898  \n",
      "82         0.062742  \n",
      "83         0.056033  \n",
      "84         0.045544  \n",
      "85         0.055766  \n",
      "86         0.052912  \n",
      "87         0.040458  \n",
      "88         0.059725  \n",
      "89         0.053789  \n",
      "90         0.038968  \n",
      "91         0.066514  \n",
      "92         0.059910  \n",
      "93         0.035905  \n",
      "94         0.062574  \n",
      "95         0.053880  \n",
      "96         0.036163  \n",
      "97         0.058998  \n",
      "98         0.059112  \n",
      "99         0.038378  \n",
      "100        0.057259  \n",
      "101        0.060537  \n",
      "102        0.039802  \n",
      "103        0.057087  \n",
      "104        0.056821  \n",
      "105        0.047696  \n",
      "106        0.059136  \n",
      "107        0.056856  \n",
      "\n",
      "[108 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier - Grid Search\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'loss':['deviance', 'exponential'],\n",
    "#         'learning_rate':[0.1, 0.2, 0.3],\n",
    "#         'n_estimators':[80,90,100],\n",
    "#         'max_features':[0.6,0.7,0.8],\n",
    "#         'min_samples_leaf':[10,12,14],\n",
    "#         'min_samples_split':[3,5,7]\n",
    "#     },\n",
    "# ]\n",
    "param_grid = [\n",
    "    {\n",
    "        'loss':['exponential'],\n",
    "        'learning_rate':[0.1],\n",
    "        'n_estimators':[10,30,40],\n",
    "        'max_features':[0.1,0.2,0.3],\n",
    "        'min_samples_leaf':[7,8,9],\n",
    "        'min_samples_split':[13,15,17,19]\n",
    "    },\n",
    "]\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "\n",
    "%time grid_search.fit(train_prepared,train_2['Survived'])\n",
    "\n",
    "#let's see the best estimator\n",
    "best_gbc = grid_search.best_estimator_\n",
    "print(best_gbc)\n",
    "print(\"_\"*40)\n",
    "#with its score\n",
    "# print(np.sqrt(-grid_search.best_score_))\n",
    "print(grid_search.best_score_)\n",
    "print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
       "              max_features=0.3, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=8, min_samples_split=17,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=40,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 in progress\n",
      "Score : 0.844 : 0.827\n",
      "----------------------------------------\n",
      "Fold 1 in progress\n",
      "Score : 0.803 : 0.775\n",
      "----------------------------------------\n",
      "Fold 2 in progress\n",
      "Score : 0.826 : 0.826\n",
      "----------------------------------------\n",
      "Fold 3 in progress\n",
      "Score : 0.803 : 0.837\n",
      "----------------------------------------\n",
      "Fold 4 in progress\n",
      "Score : 0.831 : 0.815\n",
      "----------------------------------------\n",
      "Baseline RFC: 0.822 +- 0.016\n",
      "Baseline GBC: 0.816 +- 0.022\n"
     ]
    }
   ],
   "source": [
    "scores_rfc = []\n",
    "scores_gbc = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfolds.split(target)):\n",
    "    print(\"Fold {} in progress\".format(i))\n",
    "#     print(test_index)\n",
    "    result = train_2['Survived'].iloc[test_index] #Get actual answers \n",
    "    \n",
    "    #Get prepared train and test\n",
    "    train_2_prepared = full_pipeline.fit_transform(train_2.iloc[train_index])\n",
    "#     import pdb; pdb.set_trace()\n",
    "    test_2_prepared = full_pipeline.fit_transform(train_2.iloc[test_index])\n",
    "    \n",
    "    #Train estimator for train_index\n",
    "    best_rfc.fit(train_2_prepared, train_2['Survived'].iloc[train_index])\n",
    "    best_gbc.fit(train_2_prepared, train_2['Survived'].iloc[train_index])\n",
    "    \n",
    "    #Get predictions for test_index\n",
    "    pred_rfc = best_rfc.predict(test_2_prepared)\n",
    "    pred_gbc = best_gbc.predict(test_2_prepared)\n",
    "  \n",
    "    #Calculate score\n",
    "    score_rfc = accuracy_score(y_pred=pred_rfc, y_true=result) #Calculate score\n",
    "    score_gbc = accuracy_score(y_pred=pred_gbc, y_true=result) #Calculate score\n",
    "    scores_rfc.append(score_rfc)\n",
    "    scores_gbc.append(score_gbc)\n",
    "    print(\"Score : {} : {}\".format(round(score_rfc,3),round(score_gbc,3)))\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "print(\"Baseline RFC: {} +- {}\".format(round(np.mean(scores_rfc),3), round(np.std(scores_rfc),3)))\n",
    "print(\"Baseline GBC: {} +- {}\".format(round(np.mean(scores_gbc),3), round(np.std(scores_gbc),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared = full_pipeline.fit_transform(train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.7, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=7,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc.fit(train_prepared, train_2['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Fare           417 non-null float64\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 26.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0          892       3    male  34.5      0      0   7.8292        Q\n",
       "1          893       3  female  47.0      1      0   7.0000        S\n",
       "2          894       2    male  62.0      0      0   9.6875        Q\n",
       "3          895       3    male  27.0      0      0   8.6625        S\n",
       "4          896       3  female  22.0      1      1  12.2875        S\n",
       "5          897       3    male  14.0      0      0   9.2250        S\n",
       "6          898       3  female  30.0      0      0   7.6292        Q\n",
       "7          899       2    male  26.0      1      1  29.0000        S\n",
       "8          900       3  female  18.0      0      0   7.2292        C\n",
       "9          901       3    male  21.0      2      0  24.1500        S"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = df_test.drop(['Name','Ticket','Cabin'], axis=1)\n",
    "test_2.info()\n",
    "test_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prepared = full_pipeline.fit_transform(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_survived = best_rfc.predict(test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_2 = pd.DataFrame({\n",
    "    'PassengerId':test_2.PassengerId,\n",
    "    'Survived':test_survived\n",
    "})\n",
    "submission_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_2.to_csv('submission_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Features (Family Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamilySize_feature(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputes values into Embarked variable\n",
    "    \"\"\"\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        return None\n",
    "    def fit(self, X):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        # deep copy the df\n",
    "        df = X.copy()\n",
    "        df['FamilySize'] = df['Parch'] + df['SibSp']\n",
    "        return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "CAT_ATTRIBS = ['Sex','Embarked']\n",
    "NUM_ATTRIBS = ['Pclass','Age','FamilySize','Fare']\n",
    "\n",
    "# map transformers on variables\n",
    "my_mapper = DataFrameMapper([\n",
    "    ('Sex', LabelBinarizer()),\n",
    "    ('Embarked', LabelBinarizer()),\n",
    "    ], input_df=True)\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('Embarked_imputer', EmbarkedImputer()),\n",
    "    ('label_binarizer_df', my_mapper),\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('Fare_imputer', GeneralImputer(col_impute='Fare',col_group=['Sex','Pclass'], impute_method='median')),\n",
    "    ('Age_imputer', GeneralImputer(col_impute='Age',col_group=['Sex','Pclass'], impute_method='median')),\n",
    "    ('FamilySize_feature_creation', FamilySize_feature()),\n",
    "    ('Selector', DataFrameSelector(NUM_ATTRIBS)),\n",
    "    ('Scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('Num_pipeline', numerical_pipeline),\n",
    "    ('Cat_pipeline', categorical_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82737724 -0.53489116  0.05915988 ...  0.          0.\n",
      "   1.        ]\n",
      " [-1.56610693  0.66839176  0.05915988 ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.82737724 -0.23407043 -0.56097483 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.82737724 -0.57249375  1.29942929 ...  0.          0.\n",
      "   1.        ]\n",
      " [-1.56610693 -0.23407043 -0.56097483 ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.82737724  0.21716066 -0.56097483 ...  0.          1.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_prepared = full_pipeline.fit_transform(train_2)\n",
    "print(train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 2s\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=10, min_samples_split=7,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "________________________________________\n",
      "0.8294051627384961\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'bootstrap': False, 'max_features': 0.6, 'min...         0.821549   \n",
      "1    {'bootstrap': False, 'max_features': 0.6, 'min...         0.821549   \n",
      "2    {'bootstrap': False, 'max_features': 0.6, 'min...         0.823793   \n",
      "3    {'bootstrap': False, 'max_features': 0.6, 'min...         0.820426   \n",
      "4    {'bootstrap': False, 'max_features': 0.6, 'min...         0.820426   \n",
      "5    {'bootstrap': False, 'max_features': 0.6, 'min...         0.827160   \n",
      "6    {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "7    {'bootstrap': False, 'max_features': 0.6, 'min...         0.822671   \n",
      "8    {'bootstrap': False, 'max_features': 0.6, 'min...         0.824916   \n",
      "9    {'bootstrap': False, 'max_features': 0.6, 'min...         0.815937   \n",
      "10   {'bootstrap': False, 'max_features': 0.6, 'min...         0.815937   \n",
      "11   {'bootstrap': False, 'max_features': 0.6, 'min...         0.819304   \n",
      "12   {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "13   {'bootstrap': False, 'max_features': 0.6, 'min...         0.819304   \n",
      "14   {'bootstrap': False, 'max_features': 0.6, 'min...         0.817059   \n",
      "15   {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "16   {'bootstrap': False, 'max_features': 0.6, 'min...         0.821549   \n",
      "17   {'bootstrap': False, 'max_features': 0.6, 'min...         0.820426   \n",
      "18   {'bootstrap': False, 'max_features': 0.6, 'min...         0.814815   \n",
      "19   {'bootstrap': False, 'max_features': 0.6, 'min...         0.808081   \n",
      "20   {'bootstrap': False, 'max_features': 0.6, 'min...         0.815937   \n",
      "21   {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "22   {'bootstrap': False, 'max_features': 0.6, 'min...         0.813692   \n",
      "23   {'bootstrap': False, 'max_features': 0.6, 'min...         0.817059   \n",
      "24   {'bootstrap': False, 'max_features': 0.6, 'min...         0.810325   \n",
      "25   {'bootstrap': False, 'max_features': 0.6, 'min...         0.810325   \n",
      "26   {'bootstrap': False, 'max_features': 0.6, 'min...         0.813692   \n",
      "27   {'bootstrap': False, 'max_features': 0.7, 'min...         0.826038   \n",
      "28   {'bootstrap': False, 'max_features': 0.7, 'min...         0.827160   \n",
      "29   {'bootstrap': False, 'max_features': 0.7, 'min...         0.826038   \n",
      "..                                                 ...              ...   \n",
      "132  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.806958   \n",
      "133  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.810325   \n",
      "134  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.803591   \n",
      "135  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.814815   \n",
      "136  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "137  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.812570   \n",
      "138  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "139  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.812570   \n",
      "140  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.814815   \n",
      "141  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.815937   \n",
      "142  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.817059   \n",
      "143  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.815937   \n",
      "144  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.809203   \n",
      "145  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "146  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "147  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.810325   \n",
      "148  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "149  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.813692   \n",
      "150  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.806958   \n",
      "151  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.809203   \n",
      "152  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.802469   \n",
      "153  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.803591   \n",
      "154  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.802469   \n",
      "155  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.805836   \n",
      "156  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "157  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "158  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.805836   \n",
      "159  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.806958   \n",
      "160  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.802469   \n",
      "161  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.030585  \n",
      "1          0.028727  \n",
      "2          0.027117  \n",
      "3          0.026023  \n",
      "4          0.025327  \n",
      "5          0.024682  \n",
      "6          0.032567  \n",
      "7          0.035653  \n",
      "8          0.032579  \n",
      "9          0.021482  \n",
      "10         0.023032  \n",
      "11         0.027489  \n",
      "12         0.020871  \n",
      "13         0.023738  \n",
      "14         0.024662  \n",
      "15         0.027042  \n",
      "16         0.025294  \n",
      "17         0.022931  \n",
      "18         0.028602  \n",
      "19         0.020903  \n",
      "20         0.029019  \n",
      "21         0.023433  \n",
      "22         0.023791  \n",
      "23         0.024549  \n",
      "24         0.021244  \n",
      "25         0.021244  \n",
      "26         0.023734  \n",
      "27         0.026484  \n",
      "28         0.024216  \n",
      "29         0.030599  \n",
      "..              ...  \n",
      "132        0.017877  \n",
      "133        0.018183  \n",
      "134        0.016892  \n",
      "135        0.023153  \n",
      "136        0.024572  \n",
      "137        0.021926  \n",
      "138        0.029054  \n",
      "139        0.023849  \n",
      "140        0.026868  \n",
      "141        0.034195  \n",
      "142        0.023452  \n",
      "143        0.031154  \n",
      "144        0.026963  \n",
      "145        0.023540  \n",
      "146        0.019340  \n",
      "147        0.025455  \n",
      "148        0.025869  \n",
      "149        0.022260  \n",
      "150        0.027615  \n",
      "151        0.024919  \n",
      "152        0.021380  \n",
      "153        0.015250  \n",
      "154        0.019422  \n",
      "155        0.021989  \n",
      "156        0.018445  \n",
      "157        0.018206  \n",
      "158        0.020619  \n",
      "159        0.018023  \n",
      "160        0.024198  \n",
      "161        0.017576  \n",
      "\n",
      "[162 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier - Grid Search\n",
    "param_grid = [\n",
    "    {\n",
    "        'bootstrap':[False, True],\n",
    "        'n_estimators':[80,90,100],\n",
    "        'max_features':[0.6,0.7,0.8],\n",
    "        'min_samples_leaf':[10,12,14],\n",
    "        'min_samples_split':[3,5,7]\n",
    "    },\n",
    "]\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "# grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='neg_mean_squared_error', refit=True)\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "\n",
    "%time grid_search.fit(train_prepared,train_2['Survived'])\n",
    "\n",
    "#let's see the best estimator\n",
    "best_rfc = grid_search.best_estimator_\n",
    "print(best_rfc)\n",
    "print(\"_\"*40)\n",
    "#with its score\n",
    "# print(np.sqrt(-grid_search.best_score_))\n",
    "print(grid_search.best_score_)\n",
    "print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=7,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.5 s\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "              max_features=0.1, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=9, min_samples_split=19,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "________________________________________\n",
      "0.8249158249158249\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.768799   \n",
      "1    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.809203   \n",
      "2    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "3    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.786756   \n",
      "4    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.805836   \n",
      "5    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "6    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.775533   \n",
      "7    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.809203   \n",
      "8    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.820426   \n",
      "9    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.778900   \n",
      "10   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.808081   \n",
      "11   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.809203   \n",
      "12   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.774411   \n",
      "13   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.818182   \n",
      "14   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "15   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.757576   \n",
      "16   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.812570   \n",
      "17   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "18   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.784512   \n",
      "19   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "20   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "21   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.756453   \n",
      "22   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.810325   \n",
      "23   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "24   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.763187   \n",
      "25   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.818182   \n",
      "26   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.818182   \n",
      "27   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.749719   \n",
      "28   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "29   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "..                                                 ...              ...   \n",
      "78   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.793490   \n",
      "79   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "80   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "81   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.795735   \n",
      "82   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "83   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.824916   \n",
      "84   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.796857   \n",
      "85   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.820426   \n",
      "86   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.817059   \n",
      "87   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.796857   \n",
      "88   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "89   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.810325   \n",
      "90   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.790123   \n",
      "91   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.812570   \n",
      "92   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.817059   \n",
      "93   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.809203   \n",
      "94   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.810325   \n",
      "95   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.817059   \n",
      "96   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.786756   \n",
      "97   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.818182   \n",
      "98   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.822671   \n",
      "99   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.792368   \n",
      "100  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "101  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "102  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.805836   \n",
      "103  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.810325   \n",
      "104  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "105  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.793490   \n",
      "106  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "107  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.059798  \n",
      "1          0.027816  \n",
      "2          0.024309  \n",
      "3          0.024309  \n",
      "4          0.023852  \n",
      "5          0.022969  \n",
      "6          0.024265  \n",
      "7          0.028976  \n",
      "8          0.028191  \n",
      "9          0.034439  \n",
      "10         0.029555  \n",
      "11         0.020511  \n",
      "12         0.044287  \n",
      "13         0.017002  \n",
      "14         0.026927  \n",
      "15         0.033156  \n",
      "16         0.017806  \n",
      "17         0.026848  \n",
      "18         0.028346  \n",
      "19         0.020774  \n",
      "20         0.030360  \n",
      "21         0.053935  \n",
      "22         0.023504  \n",
      "23         0.022232  \n",
      "24         0.056264  \n",
      "25         0.024429  \n",
      "26         0.029541  \n",
      "27         0.064374  \n",
      "28         0.025966  \n",
      "29         0.022748  \n",
      "..              ...  \n",
      "78         0.025899  \n",
      "79         0.018085  \n",
      "80         0.017818  \n",
      "81         0.035413  \n",
      "82         0.019867  \n",
      "83         0.018275  \n",
      "84         0.021986  \n",
      "85         0.026849  \n",
      "86         0.030513  \n",
      "87         0.030258  \n",
      "88         0.021564  \n",
      "89         0.020987  \n",
      "90         0.024866  \n",
      "91         0.021680  \n",
      "92         0.020493  \n",
      "93         0.026505  \n",
      "94         0.027800  \n",
      "95         0.017137  \n",
      "96         0.021155  \n",
      "97         0.026721  \n",
      "98         0.020566  \n",
      "99         0.022044  \n",
      "100        0.024584  \n",
      "101        0.017680  \n",
      "102        0.023866  \n",
      "103        0.027800  \n",
      "104        0.024215  \n",
      "105        0.043446  \n",
      "106        0.019195  \n",
      "107        0.014980  \n",
      "\n",
      "[108 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier - Grid Search\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'loss':['deviance', 'exponential'],\n",
    "#         'learning_rate':[0.1, 0.2, 0.3],\n",
    "#         'n_estimators':[80,90,100],\n",
    "#         'max_features':[0.6,0.7,0.8],\n",
    "#         'min_samples_leaf':[10,12,14],\n",
    "#         'min_samples_split':[3,5,7]\n",
    "#     },\n",
    "# ]\n",
    "param_grid = [\n",
    "    {\n",
    "        'loss':['exponential'],\n",
    "        'learning_rate':[0.1],\n",
    "        'n_estimators':[10,30,40],\n",
    "        'max_features':[0.1,0.2,0.3],\n",
    "        'min_samples_leaf':[7,8,9],\n",
    "        'min_samples_split':[13,15,17,19]\n",
    "    },\n",
    "]\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "\n",
    "%time grid_search.fit(train_prepared,train_2['Survived'])\n",
    "\n",
    "#let's see the best estimator\n",
    "best_gbc = grid_search.best_estimator_\n",
    "print(best_gbc)\n",
    "print(\"_\"*40)\n",
    "#with its score\n",
    "# print(np.sqrt(-grid_search.best_score_))\n",
    "print(grid_search.best_score_)\n",
    "print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
       "              max_features=0.1, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=9, min_samples_split=19,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 in progress\n",
      "RandomForestClassifier Score : 0.838\n",
      "GradientBoostedClassifier Score : 0.793\n",
      "----------------------------------------\n",
      "Fold 1 in progress\n",
      "RandomForestClassifier Score : 0.792\n",
      "GradientBoostedClassifier Score : 0.758\n",
      "----------------------------------------\n",
      "Fold 2 in progress\n",
      "RandomForestClassifier Score : 0.809\n",
      "GradientBoostedClassifier Score : 0.815\n",
      "----------------------------------------\n",
      "Fold 3 in progress\n",
      "RandomForestClassifier Score : 0.831\n",
      "GradientBoostedClassifier Score : 0.848\n",
      "----------------------------------------\n",
      "Fold 4 in progress\n",
      "RandomForestClassifier Score : 0.815\n",
      "GradientBoostedClassifier Score : 0.775\n",
      "----------------------------------------\n",
      "Baseline RandomForestClassifier:\t 0.817 +- 0.016\n",
      "Baseline GradientBoostedClassifier:\t 0.798 +- 0.031\n"
     ]
    }
   ],
   "source": [
    "estimator = [\n",
    "    ('RandomForestClassifier',best_rfc),\n",
    "    ('GradientBoostedClassifier',best_gbc),\n",
    "]\n",
    "\n",
    "scores = [[],[]]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfolds.split(target)):\n",
    "    print(\"Fold {} in progress\".format(i))\n",
    "    for k in enumerate(estimator):\n",
    "        result = train_2['Survived'].iloc[test_index] #Get actual answers \n",
    "\n",
    "        #Get prepared train and test\n",
    "        train_2_prepared = full_pipeline.fit_transform(train_2.iloc[train_index])\n",
    "    #     import pdb; pdb.set_trace()\n",
    "        test_2_prepared = full_pipeline.fit_transform(train_2.iloc[test_index])\n",
    "\n",
    "        #Train estimator for train_index\n",
    "        estimator[k[0]][1].fit(train_2_prepared, train_2['Survived'].iloc[train_index])\n",
    "\n",
    "        #Get predictions for test_index\n",
    "        pred = estimator[k[0]][1].predict(test_2_prepared)\n",
    "\n",
    "        #Calculate score\n",
    "        score = accuracy_score(y_pred=pred, y_true=result) #Calculate score\n",
    "        scores[k[0]].append(score)\n",
    "        print(\"{} Score : {}\".format(estimator[k[0]][0],round(score,3)))\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "\n",
    "for k in enumerate(estimator):\n",
    "    print(\"Baseline {}:\\t {} +- {}\".format(estimator[k[0]][0],round(np.mean(scores[k[0]]),3), round(np.std(scores[k[0]]),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared = full_pipeline.fit_transform(train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=7,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc.fit(train_prepared, train_2['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Fare           417 non-null float64\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 26.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0          892       3    male  34.5      0      0   7.8292        Q\n",
       "1          893       3  female  47.0      1      0   7.0000        S\n",
       "2          894       2    male  62.0      0      0   9.6875        Q\n",
       "3          895       3    male  27.0      0      0   8.6625        S\n",
       "4          896       3  female  22.0      1      1  12.2875        S\n",
       "5          897       3    male  14.0      0      0   9.2250        S\n",
       "6          898       3  female  30.0      0      0   7.6292        Q\n",
       "7          899       2    male  26.0      1      1  29.0000        S\n",
       "8          900       3  female  18.0      0      0   7.2292        C\n",
       "9          901       3    male  21.0      2      0  24.1500        S"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = df_test.drop(['Name','Ticket','Cabin'], axis=1)\n",
    "test_2.info()\n",
    "test_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prepared = full_pipeline.fit_transform(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_survived = best_rfc.predict(test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_3 = pd.DataFrame({\n",
    "    'PassengerId':test_2.PassengerId,\n",
    "    'Survived':test_survived\n",
    "})\n",
    "submission_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_3.to_csv('submission_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Features (Adjusted Fare Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FareAdjusted_feature(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputes values into Embarked variable\n",
    "    \"\"\"\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        return None\n",
    "    def fit(self, X):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        # deep copy the df\n",
    "        df = X.copy()\n",
    "        \n",
    "        df['TicketFrequency'] = train_4.groupby(['Ticket'])['Ticket'].transform('count')\n",
    "#         for i in np.arange(df.shape[0]):\n",
    "#             df['TicketFrequency'].iloc[i] = train_4.Ticket.loc[train_4.Ticket == train_4.Ticket.iloc[i]].count()\n",
    "        \n",
    "        df['FareAdj'] = df['Fare']/df['TicketFrequency']    \n",
    "        return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(3)\n",
      "memory usage: 69.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "5            6         0       3    male   NaN      0      0   \n",
       "6            7         0       1    male  54.0      0      0   \n",
       "7            8         0       3    male   2.0      3      1   \n",
       "8            9         1       3  female  27.0      0      2   \n",
       "9           10         1       2  female  14.0      1      0   \n",
       "\n",
       "             Ticket     Fare Embarked  \n",
       "0         A/5 21171   7.2500        S  \n",
       "1          PC 17599  71.2833        C  \n",
       "2  STON/O2. 3101282   7.9250        S  \n",
       "3            113803  53.1000        S  \n",
       "4            373450   8.0500        S  \n",
       "5            330877   8.4583        Q  \n",
       "6             17463  51.8625        S  \n",
       "7            349909  21.0750        S  \n",
       "8            347742  11.1333        S  \n",
       "9            237736  30.0708        C  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_3 = df_train.drop(['Name','Cabin','prediction'], axis=1)\n",
    "train_3.info()\n",
    "train_3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketFrequency</th>\n",
       "      <th>FareAdj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>71.28330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>7.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>26.55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>8.05000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>51.86250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>5.26875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>3.71110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>15.03540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "5            6         0       3    male   NaN      0      0   \n",
       "6            7         0       1    male  54.0      0      0   \n",
       "7            8         0       3    male   2.0      3      1   \n",
       "8            9         1       3  female  27.0      0      2   \n",
       "9           10         1       2  female  14.0      1      0   \n",
       "\n",
       "             Ticket     Fare Embarked  TicketFrequency   FareAdj  \n",
       "0         A/5 21171   7.2500        S                1   7.25000  \n",
       "1          PC 17599  71.2833        C                1  71.28330  \n",
       "2  STON/O2. 3101282   7.9250        S                1   7.92500  \n",
       "3            113803  53.1000        S                2  26.55000  \n",
       "4            373450   8.0500        S                1   8.05000  \n",
       "5            330877   8.4583        Q                1   8.45830  \n",
       "6             17463  51.8625        S                1  51.86250  \n",
       "7            349909  21.0750        S                4   5.26875  \n",
       "8            347742  11.1333        S                3   3.71110  \n",
       "9            237736  30.0708        C                2  15.03540  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_4 = FareAdjusted_feature.transform(train_3, train_3)\n",
    "train_4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "CAT_ATTRIBS = ['Sex','Embarked']\n",
    "NUM_ATTRIBS = ['Pclass','Age','FamilySize','FareAdj']\n",
    "\n",
    "# map transformers on variables\n",
    "my_mapper = DataFrameMapper([\n",
    "    ('Sex', LabelBinarizer()),\n",
    "    ('Embarked', LabelBinarizer()),\n",
    "    ], input_df=True)\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('Embarked_imputer', EmbarkedImputer()),\n",
    "    ('label_binarizer_df', my_mapper),\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('Fare_imputer', GeneralImputer(col_impute='Fare',col_group=['Sex','Pclass'], impute_method='median')),\n",
    "    ('Age_imputer', GeneralImputer(col_impute='Age',col_group=['Sex','Pclass'], impute_method='median')),\n",
    "    ('FamilySize_feature_creation', FamilySize_feature()),\n",
    "    ('Fare_Adjustments',FareAdjusted_feature()),\n",
    "    ('Selector', DataFrameSelector(NUM_ATTRIBS)),\n",
    "    ('Scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('Num_pipeline', numerical_pipeline),\n",
    "    ('Cat_pipeline', categorical_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82737724 -0.53489116  0.05915988 ...  0.          0.\n",
      "   1.        ]\n",
      " [-1.56610693  0.66839176  0.05915988 ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.82737724 -0.23407043 -0.56097483 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.82737724 -0.57249375  1.29942929 ...  0.          0.\n",
      "   1.        ]\n",
      " [-1.56610693 -0.23407043 -0.56097483 ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.82737724  0.21716066 -0.56097483 ...  0.          1.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_prepared = full_pipeline.fit_transform(train_3)\n",
    "print(train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 51s\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=12, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "________________________________________\n",
      "0.8260381593714927\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "1    {'bootstrap': False, 'max_features': 0.6, 'min...         0.822671   \n",
      "2    {'bootstrap': False, 'max_features': 0.6, 'min...         0.820426   \n",
      "3    {'bootstrap': False, 'max_features': 0.6, 'min...         0.815937   \n",
      "4    {'bootstrap': False, 'max_features': 0.6, 'min...         0.823793   \n",
      "5    {'bootstrap': False, 'max_features': 0.6, 'min...         0.821549   \n",
      "6    {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "7    {'bootstrap': False, 'max_features': 0.6, 'min...         0.817059   \n",
      "8    {'bootstrap': False, 'max_features': 0.6, 'min...         0.819304   \n",
      "9    {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "10   {'bootstrap': False, 'max_features': 0.6, 'min...         0.813692   \n",
      "11   {'bootstrap': False, 'max_features': 0.6, 'min...         0.817059   \n",
      "12   {'bootstrap': False, 'max_features': 0.6, 'min...         0.814815   \n",
      "13   {'bootstrap': False, 'max_features': 0.6, 'min...         0.820426   \n",
      "14   {'bootstrap': False, 'max_features': 0.6, 'min...         0.826038   \n",
      "15   {'bootstrap': False, 'max_features': 0.6, 'min...         0.812570   \n",
      "16   {'bootstrap': False, 'max_features': 0.6, 'min...         0.818182   \n",
      "17   {'bootstrap': False, 'max_features': 0.6, 'min...         0.821549   \n",
      "18   {'bootstrap': False, 'max_features': 0.6, 'min...         0.819304   \n",
      "19   {'bootstrap': False, 'max_features': 0.6, 'min...         0.815937   \n",
      "20   {'bootstrap': False, 'max_features': 0.6, 'min...         0.817059   \n",
      "21   {'bootstrap': False, 'max_features': 0.6, 'min...         0.819304   \n",
      "22   {'bootstrap': False, 'max_features': 0.6, 'min...         0.813692   \n",
      "23   {'bootstrap': False, 'max_features': 0.6, 'min...         0.812570   \n",
      "24   {'bootstrap': False, 'max_features': 0.6, 'min...         0.812570   \n",
      "25   {'bootstrap': False, 'max_features': 0.6, 'min...         0.817059   \n",
      "26   {'bootstrap': False, 'max_features': 0.6, 'min...         0.815937   \n",
      "27   {'bootstrap': False, 'max_features': 0.7, 'min...         0.817059   \n",
      "28   {'bootstrap': False, 'max_features': 0.7, 'min...         0.818182   \n",
      "29   {'bootstrap': False, 'max_features': 0.7, 'min...         0.815937   \n",
      "..                                                 ...              ...   \n",
      "132  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.812570   \n",
      "133  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.806958   \n",
      "134  {'bootstrap': True, 'max_features': 0.7, 'min_...         0.810325   \n",
      "135  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.805836   \n",
      "136  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.824916   \n",
      "137  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.818182   \n",
      "138  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.812570   \n",
      "139  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.817059   \n",
      "140  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.815937   \n",
      "141  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.812570   \n",
      "142  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.814815   \n",
      "143  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.813692   \n",
      "144  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "145  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "146  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.809203   \n",
      "147  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "148  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "149  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "150  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.810325   \n",
      "151  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.811448   \n",
      "152  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.806958   \n",
      "153  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.813692   \n",
      "154  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.815937   \n",
      "155  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "156  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.809203   \n",
      "157  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "158  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.809203   \n",
      "159  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.805836   \n",
      "160  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.803591   \n",
      "161  {'bootstrap': True, 'max_features': 0.8, 'min_...         0.808081   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.024180  \n",
      "1          0.025464  \n",
      "2          0.022484  \n",
      "3          0.022106  \n",
      "4          0.017626  \n",
      "5          0.019386  \n",
      "6          0.024786  \n",
      "7          0.021340  \n",
      "8          0.023684  \n",
      "9          0.021600  \n",
      "10         0.025451  \n",
      "11         0.021024  \n",
      "12         0.029001  \n",
      "13         0.019485  \n",
      "14         0.016399  \n",
      "15         0.019892  \n",
      "16         0.021082  \n",
      "17         0.018897  \n",
      "18         0.020095  \n",
      "19         0.021958  \n",
      "20         0.019374  \n",
      "21         0.014616  \n",
      "22         0.019929  \n",
      "23         0.016563  \n",
      "24         0.019492  \n",
      "25         0.020524  \n",
      "26         0.017336  \n",
      "27         0.023110  \n",
      "28         0.017851  \n",
      "29         0.025101  \n",
      "..              ...  \n",
      "132        0.019985  \n",
      "133        0.019858  \n",
      "134        0.018861  \n",
      "135        0.021508  \n",
      "136        0.020021  \n",
      "137        0.019603  \n",
      "138        0.024679  \n",
      "139        0.022622  \n",
      "140        0.023608  \n",
      "141        0.017497  \n",
      "142        0.024966  \n",
      "143        0.020911  \n",
      "144        0.019205  \n",
      "145        0.024685  \n",
      "146        0.020157  \n",
      "147        0.020354  \n",
      "148        0.022311  \n",
      "149        0.018160  \n",
      "150        0.019175  \n",
      "151        0.015851  \n",
      "152        0.016538  \n",
      "153        0.017643  \n",
      "154        0.019134  \n",
      "155        0.019280  \n",
      "156        0.018526  \n",
      "157        0.020354  \n",
      "158        0.013121  \n",
      "159        0.019738  \n",
      "160        0.028225  \n",
      "161        0.015597  \n",
      "\n",
      "[162 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier - Grid Search\n",
    "param_grid = [\n",
    "    {\n",
    "        'bootstrap':[False, True],\n",
    "        'n_estimators':[80,90,100],\n",
    "        'max_features':[0.6,0.7,0.8],\n",
    "        'min_samples_leaf':[10,12,14],\n",
    "        'min_samples_split':[3,5,7]\n",
    "    },\n",
    "]\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "# grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='neg_mean_squared_error', refit=True)\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "\n",
    "%time grid_search.fit(train_prepared,train_3['Survived'])\n",
    "\n",
    "#let's see the best estimator\n",
    "best_rfc = grid_search.best_estimator_\n",
    "print(best_rfc)\n",
    "print(\"_\"*40)\n",
    "#with its score\n",
    "# print(np.sqrt(-grid_search.best_score_))\n",
    "print(grid_search.best_score_)\n",
    "print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=12, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.7 s\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "              max_features=0.2, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=8, min_samples_split=13,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "________________________________________\n",
      "0.8249158249158249\n",
      "                                                params  mean_test_score  \\\n",
      "0    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.755331   \n",
      "1    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.809203   \n",
      "2    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "3    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.780022   \n",
      "4    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "5    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "6    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "7    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "8    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.812570   \n",
      "9    {'learning_rate': 0.1, 'loss': 'exponential', ...         0.765432   \n",
      "10   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "11   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.821549   \n",
      "12   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.769921   \n",
      "13   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.813692   \n",
      "14   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.817059   \n",
      "15   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.775533   \n",
      "16   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.818182   \n",
      "17   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.813692   \n",
      "18   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.780022   \n",
      "19   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.805836   \n",
      "20   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.818182   \n",
      "21   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.794613   \n",
      "22   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.808081   \n",
      "23   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.817059   \n",
      "24   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.760943   \n",
      "25   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "26   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "27   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.777778   \n",
      "28   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "29   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.810325   \n",
      "..                                                 ...              ...   \n",
      "78   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.782267   \n",
      "79   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "80   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "81   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "82   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.818182   \n",
      "83   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "84   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.805836   \n",
      "85   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "86   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "87   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.793490   \n",
      "88   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.824916   \n",
      "89   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "90   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.794613   \n",
      "91   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.817059   \n",
      "92   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "93   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.803591   \n",
      "94   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "95   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.813692   \n",
      "96   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.795735   \n",
      "97   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "98   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.815937   \n",
      "99   {'learning_rate': 0.1, 'loss': 'exponential', ...         0.793490   \n",
      "100  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.819304   \n",
      "101  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.814815   \n",
      "102  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.797980   \n",
      "103  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.813692   \n",
      "104  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.811448   \n",
      "105  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.802469   \n",
      "106  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.821549   \n",
      "107  {'learning_rate': 0.1, 'loss': 'exponential', ...         0.823793   \n",
      "\n",
      "     std_test_score  \n",
      "0          0.055463  \n",
      "1          0.016965  \n",
      "2          0.024282  \n",
      "3          0.016631  \n",
      "4          0.008100  \n",
      "5          0.018639  \n",
      "6          0.009901  \n",
      "7          0.017976  \n",
      "8          0.012475  \n",
      "9          0.033641  \n",
      "10         0.016459  \n",
      "11         0.018105  \n",
      "12         0.048105  \n",
      "13         0.026361  \n",
      "14         0.014657  \n",
      "15         0.026334  \n",
      "16         0.020703  \n",
      "17         0.016147  \n",
      "18         0.051547  \n",
      "19         0.016817  \n",
      "20         0.021121  \n",
      "21         0.031414  \n",
      "22         0.024971  \n",
      "23         0.018357  \n",
      "24         0.043853  \n",
      "25         0.015023  \n",
      "26         0.011689  \n",
      "27         0.021533  \n",
      "28         0.020425  \n",
      "29         0.014275  \n",
      "..              ...  \n",
      "78         0.022891  \n",
      "79         0.014065  \n",
      "80         0.012268  \n",
      "81         0.020491  \n",
      "82         0.021017  \n",
      "83         0.019705  \n",
      "84         0.027558  \n",
      "85         0.016915  \n",
      "86         0.020174  \n",
      "87         0.026499  \n",
      "88         0.010528  \n",
      "89         0.014112  \n",
      "90         0.022629  \n",
      "91         0.012021  \n",
      "92         0.018024  \n",
      "93         0.029724  \n",
      "94         0.014691  \n",
      "95         0.012810  \n",
      "96         0.042600  \n",
      "97         0.017811  \n",
      "98         0.012181  \n",
      "99         0.029512  \n",
      "100        0.015531  \n",
      "101        0.018072  \n",
      "102        0.023255  \n",
      "103        0.015786  \n",
      "104        0.013627  \n",
      "105        0.031053  \n",
      "106        0.021536  \n",
      "107        0.015820  \n",
      "\n",
      "[108 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier - Grid Search\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'loss':['deviance', 'exponential'],\n",
    "#         'learning_rate':[0.1, 0.2, 0.3],\n",
    "#         'n_estimators':[80,90,100],\n",
    "#         'max_features':[0.6,0.7,0.8],\n",
    "#         'min_samples_leaf':[10,12,14],\n",
    "#         'min_samples_split':[3,5,7]\n",
    "#     },\n",
    "# ]\n",
    "param_grid = [\n",
    "    {\n",
    "        'loss':['exponential'],\n",
    "        'learning_rate':[0.1],\n",
    "        'n_estimators':[10,30,40],\n",
    "        'max_features':[0.1,0.2,0.3],\n",
    "        'min_samples_leaf':[7,8,9],\n",
    "        'min_samples_split':[13,15,17,19]\n",
    "    },\n",
    "]\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "\n",
    "%time grid_search.fit(train_prepared,train_3['Survived'])\n",
    "\n",
    "#let's see the best estimator\n",
    "best_gbc = grid_search.best_estimator_\n",
    "print(best_gbc)\n",
    "print(\"_\"*40)\n",
    "#with its score\n",
    "# print(np.sqrt(-grid_search.best_score_))\n",
    "print(grid_search.best_score_)\n",
    "print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
       "              max_features=0.2, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=8, min_samples_split=13,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 in progress\n",
      "RandomForestClassifier Score : 0.827\n",
      "GradientBoostedClassifier Score : 0.838\n",
      "----------------------------------------\n",
      "Fold 1 in progress\n",
      "RandomForestClassifier Score : 0.781\n",
      "GradientBoostedClassifier Score : 0.803\n",
      "----------------------------------------\n",
      "Fold 2 in progress\n",
      "RandomForestClassifier Score : 0.798\n",
      "GradientBoostedClassifier Score : 0.815\n",
      "----------------------------------------\n",
      "Fold 3 in progress\n",
      "RandomForestClassifier Score : 0.803\n",
      "GradientBoostedClassifier Score : 0.871\n",
      "----------------------------------------\n",
      "Fold 4 in progress\n",
      "RandomForestClassifier Score : 0.792\n",
      "GradientBoostedClassifier Score : 0.787\n",
      "----------------------------------------\n",
      "Baseline RandomForestClassifier:\t 0.8 +- 0.015\n",
      "Baseline GradientBoostedClassifier:\t 0.823 +- 0.029\n"
     ]
    }
   ],
   "source": [
    "estimator = [\n",
    "    ('RandomForestClassifier',best_rfc),\n",
    "    ('GradientBoostedClassifier',best_gbc),\n",
    "]\n",
    "\n",
    "scores = [[],[]]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfolds.split(target)):\n",
    "    print(\"Fold {} in progress\".format(i))\n",
    "    for k in enumerate(estimator):\n",
    "        result = train_3['Survived'].iloc[test_index] #Get actual answers \n",
    "\n",
    "        #Get prepared train and test\n",
    "        train_3_prepared = full_pipeline.fit_transform(train_3.iloc[train_index])\n",
    "    #     import pdb; pdb.set_trace()\n",
    "        test_3_prepared = full_pipeline.fit_transform(train_3.iloc[test_index])\n",
    "\n",
    "        #Train estimator for train_index\n",
    "        estimator[k[0]][1].fit(train_3_prepared, train_3['Survived'].iloc[train_index])\n",
    "\n",
    "        #Get predictions for test_index\n",
    "        pred = estimator[k[0]][1].predict(test_3_prepared)\n",
    "\n",
    "        #Calculate score\n",
    "        score = accuracy_score(y_pred=pred, y_true=result) #Calculate score\n",
    "        scores[k[0]].append(score)\n",
    "        print(\"{} Score : {}\".format(estimator[k[0]][0],round(score,3)))\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "\n",
    "for k in enumerate(estimator):\n",
    "    print(\"Baseline {}:\\t {} +- {}\".format(estimator[k[0]][0],round(np.mean(scores[k[0]]),3), round(np.std(scores[k[0]]),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared = full_pipeline.fit_transform(train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_survived = best_gbc.predict(test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_4 = pd.DataFrame({\n",
    "    'PassengerId':test_2.PassengerId,\n",
    "    'Survived':test_survived\n",
    "})\n",
    "submission_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_4.to_csv('submission_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Features (Woman Child Groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Title</th>\n",
       "      <th>SexGroup</th>\n",
       "      <th>WCG</th>\n",
       "      <th>WCG_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>man</td>\n",
       "      <td>NoGroup</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>woman</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>woman</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>woman</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>man</td>\n",
       "      <td>NoGroup</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  prediction Title SexGroup  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S           0    Mr      man   \n",
       "1      0          PC 17599  71.2833   C85        C           1   Mrs    woman   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S           1  Miss    woman   \n",
       "3      0            113803  53.1000  C123        S           1   Mrs    woman   \n",
       "4      0            373450   8.0500   NaN        S           0    Mr      man   \n",
       "\n",
       "         WCG  WCG_frequency  \n",
       "0    NoGroup            537  \n",
       "1    Cumings              1  \n",
       "2  Heikkinen              1  \n",
       "3   Futrelle              1  \n",
       "4    NoGroup            537  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_5 = df_train\n",
    "train_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr          517\n",
       "Miss        182\n",
       "Mrs         125\n",
       "Master       40\n",
       "Dr            7\n",
       "Rev           6\n",
       "Major         2\n",
       "Col           2\n",
       "Mlle          2\n",
       "Lady          1\n",
       "Jonkheer      1\n",
       "Countess      1\n",
       "Don           1\n",
       "Sir           1\n",
       "Ms            1\n",
       "Capt          1\n",
       "Mme           1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_5['Title'] = train_5['Name'].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "train_5.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Title</th>\n",
       "      <th>SexGroup</th>\n",
       "      <th>WCG</th>\n",
       "      <th>WCG_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>man</td>\n",
       "      <td>NoGroup</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>woman</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>woman</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>woman</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>man</td>\n",
       "      <td>NoGroup</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  prediction Title SexGroup  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S           0    Mr      man   \n",
       "1      0          PC 17599  71.2833   C85        C           1   Mrs    woman   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S           1  Miss    woman   \n",
       "3      0            113803  53.1000  C123        S           1   Mrs    woman   \n",
       "4      0            373450   8.0500   NaN        S           0    Mr      man   \n",
       "\n",
       "         WCG  WCG_frequency  \n",
       "0    NoGroup            537  \n",
       "1    Cumings              1  \n",
       "2  Heikkinen              1  \n",
       "3   Futrelle              1  \n",
       "4    NoGroup            537  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'Mr':'man','Miss':'woman','Mrs':'woman','Master':'boy',\n",
    "           'Dr':'man','Rev':'man','Major':'man','Col':'man','Mlle':'woman',\n",
    "           'Lady':'woman','Johkheer':'man','Countess':'woman','Don':'man',\n",
    "           'Sir':'man','Ms':'woman','Capt':'man','Mme':'woman'}\n",
    "\n",
    "train_5['SexGroup'] = train_5['Title'].map(mapping)\n",
    "train_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WCG         Survived\n",
       "Allison     0             2\n",
       "            1             1\n",
       "Andersson   0             6\n",
       "            1             1\n",
       "Asplund     0             1\n",
       "            1             3\n",
       "Baclini     1             4\n",
       "Barbara     0             2\n",
       "Becker      1             2\n",
       "Boulos      0             2\n",
       "Bourke      0             2\n",
       "Brown       1             3\n",
       "Caldwell    1             2\n",
       "Carter      0             1\n",
       "            1             3\n",
       "Collyer     1             2\n",
       "Coutts      1             2\n",
       "Doling      1             2\n",
       "Ford        0             3\n",
       "Fortune     1             2\n",
       "Goldsmith   1             2\n",
       "Goodwin     0             5\n",
       "Graham      1             2\n",
       "Hamalainen  1             2\n",
       "Harper      1             2\n",
       "Hart        1             2\n",
       "Hays        1             2\n",
       "Herman      1             2\n",
       "Hippach     1             2\n",
       "Impe        0             2\n",
       "Johnson     1             3\n",
       "Jussila     0             2\n",
       "Kelly       1             3\n",
       "Laroche     1             2\n",
       "Lefebre     0             4\n",
       "Mellinger   1             2\n",
       "Moor        1             2\n",
       "Moubarek    1             2\n",
       "Murphy      1             2\n",
       "Navratil    1             2\n",
       "Newell      1             2\n",
       "NoGroup     0           489\n",
       "            1           260\n",
       "Palsson     0             4\n",
       "Panula      0             4\n",
       "Peter       1             2\n",
       "Planke      0             2\n",
       "Quick       1             2\n",
       "Rice        0             5\n",
       "Richards    1             3\n",
       "Ryerson     1             2\n",
       "Sage        0             4\n",
       "Sandstrom   1             2\n",
       "Skoog       0             5\n",
       "Strom       0             2\n",
       "Taussig     1             2\n",
       "West        1             2\n",
       "Wick        1             2\n",
       "Yarred      1             2\n",
       "Zabour      0             2\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_5['WCG'] = train_5['Name'].str.extract('([A-Za-z]+)\\,',expand=False)\n",
    "train_5['WCG'].loc[train_5['SexGroup'] == 'man'] = 'NoGroup'\n",
    "train_5['WCG_frequency'] = train_5.groupby(['WCG'])['WCG'].transform('count')\n",
    "train_5['WCG'].loc[train_5['WCG_frequency'] <= 1] = 'NoGroup'\n",
    "# train_5['WCG_survived'] = train_5.groupby(['Survived','WCG'])['Survived'].transform('mean')\n",
    "# train_5['WCG_survived'].value_counts()\n",
    "gr = train_5.groupby(['WCG','Survived'])['Survived'].count()\n",
    "# gr1 = train_5.groupby(['WCG','Survived'])['Survived'].count()/train_5['WCG_frequency']\n",
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WCG_feature(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputes values into Embarked variable\n",
    "    \"\"\"\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        return None\n",
    "    def fit(self, X):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        # deep copy the df\n",
    "        df = X.copy()\n",
    "        \n",
    "        for i in np.arange(df.shape[0]):\n",
    "            df['TicketFrequency'].iloc[i] = train_4.Ticket.loc[train_4.Ticket == train_4.Ticket.iloc[i]].count()\n",
    "        \n",
    "        df['FareAdj'] = df['Fare']/df['TicketFrequency']    \n",
    "        return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.23 s\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0.5, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "________________________________________\n",
      "0.8305274971941639\n",
      "                                  params  mean_test_score  std_test_score\n",
      "0      {'booster': 'gbtree', 'gamma': 0}         0.824916        0.020106\n",
      "1    {'booster': 'gbtree', 'gamma': 0.1}         0.823793        0.019700\n",
      "2   {'booster': 'gbtree', 'gamma': 0.25}         0.828283        0.020915\n",
      "3    {'booster': 'gbtree', 'gamma': 0.5}         0.830527        0.018990\n",
      "4   {'booster': 'gbtree', 'gamma': 0.75}         0.829405        0.016152\n",
      "5      {'booster': 'gbtree', 'gamma': 1}         0.827160        0.015090\n",
      "6        {'booster': 'dart', 'gamma': 0}         0.824916        0.020106\n",
      "7      {'booster': 'dart', 'gamma': 0.1}         0.823793        0.019700\n",
      "8     {'booster': 'dart', 'gamma': 0.25}         0.828283        0.020915\n",
      "9      {'booster': 'dart', 'gamma': 0.5}         0.830527        0.018990\n",
      "10    {'booster': 'dart', 'gamma': 0.75}         0.829405        0.016152\n",
      "11       {'booster': 'dart', 'gamma': 1}         0.827160        0.015090\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier - Grid Search\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'loss':['deviance', 'exponential'],\n",
    "#         'learning_rate':[0.1, 0.2, 0.3],\n",
    "#         'n_estimators':[80,90,100],\n",
    "#         'max_features':[0.6,0.7,0.8],\n",
    "#         'min_samples_leaf':[10,12,14],\n",
    "#         'min_samples_split':[3,5,7]\n",
    "#     },\n",
    "# ]\n",
    "param_grid = [\n",
    "    {\n",
    "        'booster':['gbtree','dart'],\n",
    "        'gamma':[0,0.1,0.25,0.5,0.75,1],\n",
    "        'alpha':[0,0.1,0.25,0.5,0.75,1],\n",
    "    },\n",
    "]\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "grid_search = GridSearchCV(xgbc, param_grid, cv=5, scoring='accuracy', refit=True)\n",
    "\n",
    "\n",
    "%time grid_search.fit(train_prepared,train_3['Survived'])\n",
    "\n",
    "#let's see the best estimator\n",
    "best_xgbc = grid_search.best_estimator_\n",
    "print(best_xgbc)\n",
    "print(\"_\"*40)\n",
    "#with its score\n",
    "# print(np.sqrt(-grid_search.best_score_))\n",
    "print(grid_search.best_score_)\n",
    "print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
